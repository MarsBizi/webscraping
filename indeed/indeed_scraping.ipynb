{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6cfa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f427a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.indeed.com/jobs?q=title%3Adata%20%2460%2C000&jt=fulltime&explvl=entry_level&sort=date&limit=50&education=bachelor_degree&vjk=8b05a317f91cca42'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2fde84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list variables to scrape\n",
    "job_title = []\n",
    "company_name = []\n",
    "job_location = []\n",
    "job_salary = []\n",
    "detailed_link = []\n",
    "posted_date = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8535031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOME FUNCTIONS\n",
    "\n",
    "# Scrap web data as text\n",
    "def get_data(url):\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    return r.text\n",
    "\n",
    "# Parse all html code\n",
    "def parse_html(url):\n",
    "    raw = get_data(url)\n",
    "    soup = BeautifulSoup(raw, 'lxml')\n",
    "    \n",
    "    return soup\n",
    "\n",
    "def get_job_info(soup):\n",
    "    # access tag/class with data\n",
    "    data_str = soup.find_all('div',class_='job_seen_beacon')\n",
    "    \n",
    "    for jobs in data_str:\n",
    "        # job title\n",
    "        try:\n",
    "            job = jobs.find('h2')\n",
    "            title = job.select('span')[1].text\n",
    "            job_title.append(title)\n",
    "        except:\n",
    "            job_title.append(' ')\n",
    "        \n",
    "        # company name\n",
    "        try:\n",
    "            company = jobs.find('span', class_='companyName').text\n",
    "            company_name.append(company)\n",
    "        except:\n",
    "            company_name.append(' ')\n",
    "        \n",
    "        # job location\n",
    "        try:\n",
    "            location = jobs.find('div', class_='companyLocation').text\n",
    "            job_location.append(location)\n",
    "        except:\n",
    "            job_location.append(' ')\n",
    "        \n",
    "        # salary\n",
    "        try:\n",
    "            salary = jobs.find('div', class_='attribute_snippet').text\n",
    "            job_salary.append(salary)\n",
    "        except:\n",
    "            job_salary.append(' ')\n",
    "        \n",
    "        # posted date\n",
    "        try:\n",
    "            date = jobs.find(class_='date').text.replace('Posted', '')\n",
    "            posted_date.append(date)\n",
    "        except:\n",
    "            company_name.append(' ')\n",
    "            \n",
    "    # detailed link\n",
    "    job_data = soup.find('div', id='mosaic-provider-jobcards')\n",
    "    for a in job_data.find_all('a', class_='tapItem'):\n",
    "        try:\n",
    "            detailed_link.append('indeed.com'+a['href'])  \n",
    "        except:\n",
    "            detailed_link.append(' ')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44cf88d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let the webscraping begin!\n",
    "soup = parse_html(url)\n",
    "get_job_info(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff0077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores as dataframe\n",
    "scraped = pd.DataFrame({'title': job_title,\n",
    "                        'company' : company_name,\n",
    "                        'location' : job_location,\n",
    "                        'salary' : job_salary,\n",
    "                        'link' : detailed_link,\n",
    "                        'date' : posted_date})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51819f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as csv\n",
    "scraped.to_csv('jobs.csv', mode='a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
