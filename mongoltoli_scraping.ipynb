{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19b74c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44fdab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!! UNCOMMENT\n",
    "#url = 'https://mongoltoli.mn/dictionary/lists/'\n",
    "url = 'https://mongoltoli.mn/dictionary/lists/А'\n",
    "url = 'https://mongoltoli.mn/dictionary/detail/3234'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71edffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list for data collection\n",
    "title_list = []\n",
    "subtitle_list = []\n",
    "word_url = []\n",
    "desc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b81dbd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOME FUNCTIONS\n",
    "\n",
    "# Scrap web data as text\n",
    "def get_data(url):\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    return r.text\n",
    "\n",
    "# Parse all html code\n",
    "def parse_html(url):\n",
    "    raw = get_data(url)\n",
    "    soup = BeautifulSoup(raw, 'lxml')\n",
    "    \n",
    "    return soup\n",
    "\n",
    "\n",
    "def get_word_info(soup):\n",
    "\n",
    "    # Scrape word/title on the page\n",
    "    title_str = soup.find(class_='title')\n",
    "    #print(html_str.text.strip())\n",
    "    title_list.append(title_str.text.strip())\n",
    "    \n",
    "    # Scrape if subtitle exists\n",
    "    subtitle_str = soup.find(class_='subtitle')\n",
    "    if subtitle_str.text == '\\n':\n",
    "        subtitle_list.append('999')\n",
    "    else:\n",
    "        subtitle_list.append(subtitle_str.text)\n",
    "        \n",
    "    # Scrape description\n",
    "    desc_str = soup.find(style='text-align: justify;')\n",
    "    desc_list.append(desc_str.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdb2617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ------------------------------------------------------- \n",
    "    \n",
    "# def get_job_info(soup):\n",
    "#     # access tag/class with data\n",
    "#     data_str = soup.find_all('div',class_='job_seen_beacon')\n",
    "    \n",
    "#     for jobs in data_str:\n",
    "#         # job title\n",
    "#         try:\n",
    "#             job = jobs.find('h2')\n",
    "#             title = job.select('span')[1].text\n",
    "#             job_title.append(title)\n",
    "#         except:\n",
    "#             job_title.append(' ')\n",
    "        \n",
    "#         # company name\n",
    "#         try:\n",
    "#             company = jobs.find('span', class_='companyName').text\n",
    "#             company_name.append(company)\n",
    "#         except:\n",
    "#             company_name.append(' ')\n",
    "        \n",
    "#         # job location\n",
    "#         try:\n",
    "#             location = jobs.find('div', class_='companyLocation').text\n",
    "#             job_location.append(location)\n",
    "#         except:\n",
    "#             job_location.append(' ')\n",
    "        \n",
    "#         # salary\n",
    "#         try:\n",
    "#             salary = jobs.find('div', class_='attribute_snippet').text\n",
    "#             job_salary.append(salary)\n",
    "#         except:\n",
    "#             job_salary.append(' ')\n",
    "        \n",
    "#         # posted date\n",
    "#         try:\n",
    "#             date = jobs.find(class_='date').text.replace('Posted', '')\n",
    "#             posted_date.append(date)\n",
    "#         except:\n",
    "#             company_name.append(' ')\n",
    "            \n",
    "#     # detailed link\n",
    "#     job_data = soup.find('div', id='mosaic-provider-jobcards')\n",
    "#     for a in job_data.find_all('a', class_='tapItem'):\n",
    "#         try:\n",
    "#             detailed_link.append('indeed.com'+a['href'])  \n",
    "#         except:\n",
    "#             detailed_link.append(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24d117c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    url = 'https://mongoltoli.mn/dictionary/detail/'\n",
    "    url = url + str(i)\n",
    "    soup = parse_html(url)\n",
    "    get_word_info(soup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94d1dd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['А', 'аравдугаар зүйлийн а', 'тавын а анги', 'а үсэг эрдмийн дээж, аяга цай идээний дээж']\n",
      "['999', '999', '999', '\\r\\n\\t\\t\\t\\t\\t\\t\\t/ зүйр цэцэн үг /\\t\\t\\t\\t\\t\\t']\n",
      "['1. Монгол шинэ үсгийн цагаан толгойн эхний үсэг; 2. Нэгдүгээр гэсэн утгыг үсгээр тэмдэглэх нь: аравдугаар зүйлийн а (аравдугаар зүйлийн нэгдүгээр хэсэг), тавын а дэлгэрэнгүй...анги (тавдугаар ангийн эхний бүлэг), а үсэг эрдмийн дээж, аяга цай идээний дээж [зүйр цэцэн үг] (а. Үсэг бичиг бол эрдэм мэдлэг эзэмших эх үндэс; б. Аливаа ажил үйлсийн эхлэл гэсэн санаа), а гэж эрдэм сурдаг, аав гэж хэлд ордог [зүйр цэцэн үг] (эрдэм ухаанд суралцах, нэвтрэх түлхүүр нь бичиг үсэг сурах явдал гэсэн санаа), а үсгийн ацаг мэдэхгүй, арав хүртэл тоо мэдэхгүй [зүйр цэцэн үг] (үсэг бичиг мэдэхгүй, бичиг үсгийн боловсрол эзэмшээгүй гэсэн санаа), а, ма-гүй [зүйр цэцэн үг] (а. Бичиг үсэг үл мэдэх; б. Яриа хөөрөөгүй, яриа муутай гэсэн санаа), а, э-гүй [зүйр цэцэн үг] (а. Бичиг үсэг огт мэдэхгүй; б. Яриа хөөрөөгүй, дуугай; в. Адармаагүй, гүндүүгүй; томоотой; г. Үг үсэгчлэн буулган бичих гэсэн санаа), амандаа а-гүй, алгандаа падгүй [зүйр цэцэн үг] (эрдэм номгүй гэсэн санаа),\\xa0А ба ха\\xa0(монгол цагаан толгойн өөр нэр. Зарим газарт монгол цагаан толгойг “а,ба,ха” гэх дарааллаар жагсааж байснаас ийн нэрлэв).', 'аравдугаар зүйлийн нэгдүгээр хэсэг', 'тавдугаар ангийн эхний бүлэг', 'а. Үсэг бичиг бол эрдэм мэдлэг эзэмших эх үндэс; б. Аливаа ажил үйлсийн эхлэл гэсэн санаа']\n"
     ]
    }
   ],
   "source": [
    "print(title_list)\n",
    "print(subtitle_list)\n",
    "print(desc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2d47f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi3'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hi' + str(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546845e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a6f2b60",
   "metadata": {},
   "source": [
    "## Finalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc916e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare alphabet for url\n",
    "# mon_alph = 'А Б В Г Д Е Ё Ж З И К Л М Н О Ө П Р С Т У Ү Ф Х Ц Ч Ш Э Ю Я'\n",
    "# mon_alph = 'А'\n",
    "# mon_alph = list(mon_alph.split(' '))\n",
    "# print(mon_alph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c217278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape(url):\n",
    "#     for letter in mon_alph:\n",
    "#         updated_url = url + letter\n",
    "#         soup = get_data(updated_url)\n",
    "#         print(updated_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e85159",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130734b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
